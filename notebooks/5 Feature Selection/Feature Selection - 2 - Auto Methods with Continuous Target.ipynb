{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Selection - Automatic Methods with Continuous Target\n",
    "\n",
    "Automated feature selection is a more powerful way to select our features compared to manual feature selection, as there is statistical justification to support our decision when selecting features.\n",
    "\n",
    "This notebook will focus on automated feature selection methods when faced with continuous target variables:\n",
    "\n",
    "1. Continuous target with continuous features: Using Correlation coefficients\n",
    "2. Continuous target with categorical features: Using ANOVA technique"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Basic Packages & Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data manipulation libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import data to a pandas dataframe\n",
    "df_cars = pd.read_csv('indian cars dataset nonulls.csv')\n",
    "df_cars\n",
    "\n",
    "# Our dataset contains information about cars that are for sale, and the target variable is the CONTINUOUS starting_price."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create variable to separate target from rest of dataframe\n",
    "target_variable = df_cars['starting_price']\n",
    "target_variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selecting or Removing Continuous Features Using Pearson Correlation Coefficients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These first methods help us select or remove continuous features, so our first step is to select only numeric features. This should NOT include features that have been One Hot Encoded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define data frame of numeric columns\n",
    "df_num = df_cars.select_dtypes(include=np.number).drop(['starting_price'], axis = 1)\n",
    "df_num.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When looking at continuous features and continuous target variables, we can use correlation coefficients to see the strength of the linear relationship with the target variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Calculate correlation with the target variable\n",
    "corr_with_tgt = df_num.corrwith(target_variable).sort_values(ascending = False)\n",
    "corr_with_tgt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With these correlation coefficients, we can create a visual to easily see the magnitudes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot a bar plot of the correlation coefficients\n",
    "sns.barplot(x = corr_with_tgt.values, y = corr_with_tgt.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the bar chart visual, we can consider removing the features that have the least correlation with our target variable starting price."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Additionally, we can look for multicollinearity between our features using the `corr` function and the heatmap visual. If there is a high correlation between our features, we can consider dropping them.\n",
    "\n",
    "Generally a correlation of about +/-0.8 and up would make us seriously consider whether we should drop one of the offending features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Plot a heatmap of correlation coefficients\n",
    "plt.rcParams['figure.figsize']=(10,7)\n",
    "sns.heatmap(df_num.corr(), annot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the heat map visual, we can consider to drop features with a high correlation amongst each other to reduce multicollinearity in our data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selecting or Removing Categorical Features Using ANOVA F-score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ANOVA method helps us select or remove **categorical** features, **including** features that have been One Hot Encoded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Define data frame of categorical columns\n",
    "df_cat = df_cars.select_dtypes('object')\n",
    "df_cat.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ANOVA test is a statistical test that analyses variance between groups. It first calculates the mean of the continuous target variable for each category in the categorical column. It then performs a test to calculate whether any of these means are statistically significantly different from eachother."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# One hot encode variables (would do this with OneHotEncoder in a realworld scenario as per FE chapter.)\n",
    "df_cat_enc = pd.get_dummies(df_cat)\n",
    "df_cat_enc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the required packages for SKLearns, SelectKBest and f_regression\n",
    "from sklearn.feature_selection import SelectKBest, f_regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Define the x and y datasets\n",
    "x = df_cat_enc\n",
    "y = target_variable\n",
    "num_features = len(df_cat_enc.columns)\n",
    "\n",
    "# define the feature selection algorithm\n",
    "f_test = SelectKBest(score_func=f_regression).fit(x, y)\n",
    "\n",
    "# define the f test output results\n",
    "f_output = pd.DataFrame()\n",
    "f_output['feature'] = df_cat_enc.columns\n",
    "f_output['f_score'] = f_test.scores_\n",
    "f_output['p_value'] = f_test.pvalues_\n",
    "\n",
    "f_output = f_output.sort_values(by=['p_value'])\n",
    "# Print the test results\n",
    "print(f_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is possible to use the SelectKBest transform method to return a reduced list of features, however, we will assume manual removal of features for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# plot the scores\n",
    "sns.barplot(data = f_output, x = 'f_score', y = 'feature')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see from the bar chart above that although only a handful of values have a high F score, they come from all of our categorical features."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
