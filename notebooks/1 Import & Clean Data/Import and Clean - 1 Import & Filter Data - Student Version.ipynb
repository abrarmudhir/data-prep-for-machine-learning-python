{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing & FIltering Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we will go over the common steps to take when importing and filtering data. Importing and filtering data properly is a foundational skill, as we can easily import and work with a data file and shift through it to find specific data that fits our use case."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Basic Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Basics\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Data from CSV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this scenario we'll import a dataset of students enrolled in a school and explore ways to select and filter data of interest.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import CSV data to a pandas dataframe\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Data from Excel File"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**pd.read_excel function**\n",
    "\n",
    "- Default is to import first sheet of an Excel file. **sheet_name** argument defines which sheet the data should come from \n",
    "- **usecols** arugment defines which columns to import\n",
    "\n",
    "In addition, there are many other arguments that can be defined to specify how the file should be interpreted.\n",
    "\n",
    "Documentation here: https://pandas.pydata.org/docs/reference/api/pandas.read_excel.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import data to a pandas dataframe\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Data Using SQL Query"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we have simply defined an SQL query we want to use to retrieve data from our database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_query = \"\"\"SELECT \n",
    " \n",
    "    hist.FactID,\n",
    "    hist.Date,\n",
    "    hist.[Open],\n",
    "    hist.High,\n",
    "    hist.Low,\n",
    "    hist.[Close],\n",
    "    hist.AdjClose,\n",
    "    hist.Volume,\n",
    " \n",
    "    sec.Company,\n",
    "    sec.Symbol,\n",
    "    sec.Industry,\n",
    "    sec.IndexWeighting,\n",
    " \n",
    "    exc.Symbol AS Exchange\n",
    " \n",
    "FROM [dbo].[FactPrices_Daily] AS hist\n",
    " \n",
    "   INNER JOIN [dbo].[dimSecurity] AS sec \n",
    "      ON hist.SecurityID = sec.ID\n",
    "      \n",
    "   INNER JOIN [dbo].[dimExchange] AS exc \n",
    "      ON sec.ExchangeID = exc.ID\n",
    ";\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Data from SQL Database Using pyodbc & sqlalchemy (Windows only syntax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Depending on the SQL server type being used, and the drivers on your computer, the syntax below may be slightly different.\n",
    "\n",
    "You may need to download ODBC Driver 18 from here: https://go.microsoft.com/fwlink/?linkid=2214634"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyodbc\n",
    "import os\n",
    "import urllib\n",
    "from sqlalchemy import create_engine\n",
    "# Some other example server values are\n",
    "# server = 'localhost\\sqlexpress' # for a named instance\n",
    "# server = 'myserver,port' # to specify an alternate port\n",
    "driver = '{ODBC Driver 18 for SQL Server}'\n",
    "server = 'prod-sql-cfieducation.database.windows.net' \n",
    "database = 'StockPricesDW' \n",
    "username = 'ReportingUser'\n",
    "password = 'CFICapitalPartners789#'\n",
    "\n",
    "connection_string = f'DRIVER={driver};SERVER=tcp:{server};DATABASE={database};UID={username};PWD={password}'\n",
    "odbc_params = urllib.parse.quote_plus(connection_string)\n",
    "conn_string = f'mssql+pyodbc:///?odbc_connect={odbc_params}'\n",
    "engine = create_engine(conn_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine the sql query with the sql connection to get data from a database\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selecting Columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have several options to filter the data coming into our analysis.\n",
    "\n",
    "Options:\n",
    "- Option 1 (SQL): Select the required columns as part of our SQL SELECT statement.\n",
    "- Option 2 (Python): Select the desired columns only from the dataframe in Python.\n",
    "- Option 3 (Python): Drop the NOT required columns from the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use Option 2 above to create a new dataframe\n",
    "# Keep only the FactID and AdjClose price columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use Option 2 above to create a new dataframe from the \n",
    "# This time drop the FactID and AdjClose price columns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filter Columns\n",
    "\n",
    "We can use the `filter` function allows us to select columns based on the criteria we want. \n",
    "\n",
    "This is a very powerful way of filtering for columns, as we can systematically call for columns that meet a specific condition without having to check manually what kind of columns we have in our dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Using the filter function with regex parameters to find a column that contains a specific word\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtering Rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also filter for rows that contain a certain string in a column using the `contains` function as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Using the contains functions to find rows that contains a specific word in a column\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also filter rows/columns based on logical conditions in the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the rows of the original datframe to include only rows where GradeAverage is A\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can add additional conditions using the & symbol."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop Duplicates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generally duplicates are unwanted, although sometimes there is a clear reason why they exist. If we know that duplicates are incorrect, we can deal with them.\n",
    "\n",
    "Lets say that we want to get rid of all duplicate last names. We can first filter for any duplicate last names in our data to see if they exist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Identify any rows with duplicated last names\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that with the combination of the duplicated function and filtering with it, we found the rows that have duplicated last names. We can now use the drop_duplicates function to easily remove these."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#drop duplicates column\n",
    "\n",
    "# Show how we check for dropped duplicate \n",
    "# df_grades, look for specific index that was dropped "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1  - Importing our data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the csv file titled \"phone_marketplace_dataset_cleaning_set.csv\" and set it as a dataframe. This dataset contains information on used phone sales that happened in various marketplace platforms.\n",
    "\n",
    "Task:\n",
    "- Use the correct pandas function to import the csv file as a dataframe\n",
    "- Assign the imported dataframe to a variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the phone_marketplace_dataset_cleaning_set.csv file into a dataframe\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2  - Conditional Filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We realized that there may be potential errors in the csv file in which we must deal with. Luckily, we are able to find out the errors came from data which came from craigslist.\n",
    "\n",
    "Task:\n",
    "- Filter for data that have craigslist as a marketplace\n",
    "- From the data that have craigslist as a marketplace, filter for only iPhone 11s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the data that has craigstlist as marketplace\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Add an additional filter for iphone 11 only.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
